{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SovetovAleksey/PyTorch/blob/main/HW_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab2a6e38",
      "metadata": {
        "id": "ab2a6e38"
      },
      "source": [
        "1. Возьмите готовую модель из https://huggingface.co/models для классификации сентимента текста.\n",
        "2. Сделайте предсказания на всем df_val. Посчитайте метрику качества.\n",
        "3. Дообучите эту модель на df_train. Посчитайте метрику качества на df_val."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73c4e4fe",
      "metadata": {
        "id": "73c4e4fe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "247a5b1e",
      "metadata": {
        "id": "247a5b1e"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77ef358b",
      "metadata": {
        "id": "77ef358b"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('data/sentiment_analysis/train.csv')\n",
        "df_val = pd.read_csv('data/sentiment_analysis/val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f7c9bce",
      "metadata": {
        "id": "4f7c9bce",
        "outputId": "b92fba4c-5a4b-48f1-a301-3a1e56b43b30"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  class\n",
              "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
              "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
              "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39929fd5",
      "metadata": {
        "id": "39929fd5",
        "outputId": "56ad87b8-aaa8-471e-c2e9-bd7c7950ca60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "sentiment = pipeline(\"text-classification\", model='blanchefort/rubert-base-cased-sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f813fc28",
      "metadata": {
        "id": "f813fc28",
        "outputId": "2f21ea01-275d-4a0b-ac35-763d6fcde2a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.75162273645401}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment('я опоздал на поезд')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "342c60bf",
      "metadata": {
        "id": "342c60bf",
        "outputId": "108f6567-2079-4902-c900-7ea803d7ba40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.910189151763916}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment('я опоздал на поезд и отлично провел время')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26383014",
      "metadata": {
        "id": "26383014"
      },
      "outputs": [],
      "source": [
        "df_train['text'] = df_train['text'].apply(lambda x: x.lower())\n",
        "df_val['text'] = df_val['text'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b77fe9c",
      "metadata": {
        "id": "0b77fe9c",
        "outputId": "a0050e41-c668-420f-c68a-ebafba2ee761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  101, 14337, 33930, 77572, 10520, 84964, 15065, 33917,   102,     0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "example_text = 'Пример текста для токенизации'\n",
        "bert_input = tokenizer(example_text, padding='max_length', max_length=10,\n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "print(bert_input['input_ids'])\n",
        "print(bert_input['attention_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92c3ecb3",
      "metadata": {
        "id": "92c3ecb3"
      },
      "outputs": [],
      "source": [
        "class TwitterDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, txts, labels):\n",
        "        self._labels = labels\n",
        "\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "        self._txts = [self.tokenizer(text, padding='max_length', max_length=10,\n",
        "                                     truncation=True, return_tensors=\"pt\")\n",
        "                      for text in txts]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._txts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self._txts[index], self._labels[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4f9b9aa",
      "metadata": {
        "id": "c4f9b9aa"
      },
      "outputs": [],
      "source": [
        "y_train = df_train['class'].values\n",
        "y_val = df_val['class'].values\n",
        "\n",
        "train_dataset = TwitterDataset(df_train['text'], y_train)\n",
        "valid_dataset = TwitterDataset(df_val['text'], y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b15de9c",
      "metadata": {
        "id": "5b15de9c"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=256,\n",
        "                          shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=256,\n",
        "                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be9b8fef",
      "metadata": {
        "id": "be9b8fef"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 2)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids=x, attention_mask=mask, return_dict=False)\n",
        "        # _, pooled_output - набор эмбеддинигов слов, эмбеддинг предложения\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.sigm(linear_output)\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93b3ad0d",
      "metadata": {
        "id": "93b3ad0d",
        "outputId": "226a0020-2f8b-4239-d79a-4be451295bfc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = BertClassifier()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.linear.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79a62a9",
      "metadata": {
        "id": "e79a62a9",
        "outputId": "ca3063b4-15bb-480d-dedf-1e37b4c0ddb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████| 709/709 [3:00:32<00:00, 15.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 | Train Loss:  0.003         | Train Accuracy:  0.566         | Val Loss:  0.003         | Val Accuracy:  0.570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████| 709/709 [3:01:08<00:00, 15.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 2 | Train Loss:  0.003         | Train Accuracy:  0.573         | Val Loss:  0.003         | Val Accuracy:  0.576\n"
          ]
        }
      ],
      "source": [
        "for epoch_num in range(2):\n",
        "    total_acc_train = 0\n",
        "    total_loss_train = 0\n",
        "\n",
        "    model.train()\n",
        "    for train_input, train_label in tqdm(train_loader):\n",
        "        mask = train_input['attention_mask']\n",
        "        input_id = train_input['input_ids'].squeeze(1)\n",
        "        train_label = train_label\n",
        "\n",
        "        output = model(input_id, mask)\n",
        "\n",
        "        batch_loss = criterion(output, train_label)\n",
        "        total_loss_train += batch_loss.item()\n",
        "\n",
        "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "        total_acc_train += acc\n",
        "\n",
        "        model.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    total_loss_val, total_acc_val = 0.0, 0.0\n",
        "    for val_input, val_label in valid_loader:\n",
        "        val_label = val_label\n",
        "        mask = val_input['attention_mask']\n",
        "        input_id = val_input['input_ids'].squeeze(1)\n",
        "\n",
        "        output = model(input_id, mask)\n",
        "\n",
        "        batch_loss = criterion(output, val_label)\n",
        "        total_loss_val += batch_loss.item()\n",
        "\n",
        "        acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "        total_acc_val += acc\n",
        "\n",
        "    print(\n",
        "        f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
        "        | Train Accuracy: {total_acc_train / len(train_dataset): .3f} \\\n",
        "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
        "        | Val Accuracy: {total_acc_val / len(valid_dataset): .3f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}